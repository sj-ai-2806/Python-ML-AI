{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2f3950d9-7b0d-47d0-b02e-2773a0db9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_log_error as msle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf63a777-769d-4516-a7cd-98e2fdd5fafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "train_data = pd.read_csv('dataset/train.csv')\n",
    "product_data = pd.read_csv('dataset/product_data.csv')\n",
    "store_data = pd.read_csv('dataset/store_data.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d89fbae2-8d4f-4b4d-901f-2cf4b91651c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PARKING_SPACE_QTY  SALES_AREA_SIZE_NUM\n",
      "SEG_VALUE_NAME                                        \n",
      "MAINSTREAM                 5920.0              2153267\n",
      "UPSCALE                    1859.0               833790\n",
      "VALUE                      4412.0               735421\n",
      "                PARKING_SPACE_QTY  SALES_AREA_SIZE_NUM  park_ratio\n",
      "SEG_VALUE_NAME                                                    \n",
      "MAINSTREAM                 5920.0              2153267    0.002749\n",
      "UPSCALE                    1859.0               833790    0.002230\n",
      "VALUE                      4412.0               735421    0.005999\n"
     ]
    }
   ],
   "source": [
    "### Replace the null values of parking quantity with a value that is directly proportional to the sales area\n",
    "\n",
    "grouped = store_data.groupby('SEG_VALUE_NAME').agg({\n",
    "    'PARKING_SPACE_QTY': 'sum',\n",
    "    'SALES_AREA_SIZE_NUM': 'sum'\n",
    "})\n",
    "print(grouped)\n",
    "grouped['park_ratio']=grouped['PARKING_SPACE_QTY'] / grouped['SALES_AREA_SIZE_NUM']\n",
    "print(grouped)\n",
    "store_data['park_ratio']=store_data['SEG_VALUE_NAME'].map(grouped['park_ratio'])\n",
    "\n",
    "store_data['PARKING_SPACE_QTY'] = store_data.apply(\n",
    "    lambda row: row['park_ratio'] * row['SALES_AREA_SIZE_NUM'] if pd.isnull(row['PARKING_SPACE_QTY']) else row['PARKING_SPACE_QTY'], axis=1\n",
    ")\n",
    "store_data.drop(columns=['park_ratio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e8b74508-5331-4eae-9755-fff3ff429f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "### I'm converting the product_size column into INT and and adding 2 columns \"NUmber of alternatives\" and number of \"alternatives of lower size\". \n",
    "\n",
    "import re\n",
    "product_data['PRODUCT_SIZE'] = product_data['PRODUCT_SIZE'].apply(lambda x: float(re.findall(r'\\d*\\.?\\d+', x)[0]))\n",
    "\n",
    "product_data['num_alternatives'] = product_data.groupby('SUB_CATEGORY')['UPC'].transform('count') - 1\n",
    "def count_lower_size(row, product_data):\n",
    "    group = product_data[(product_data['SUB_CATEGORY'] == row['SUB_CATEGORY']) &\n",
    "               (product_data['PRODUCT_SIZE'] < row['PRODUCT_SIZE'])]\n",
    "    return len(group)\n",
    "\n",
    "product_data['num_lower_size_alternatives'] = product_data.apply(count_lower_size, axis=1, product_data=product_data)\n",
    "\n",
    "product_data.to_csv('update_product_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc914b7c-dd6d-4dca-a9a9-d18b80eb308e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beb2206-0659-4454-8787-0c7862944cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d6dfa370-30a2-4180-bafd-113a2eb03256",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merged_data = train_data.merge(product_data, how= 'left', on= 'UPC')\n",
    "merged_data = merged_data.merge(store_data,how='left', left_on = 'STORE_NUM', right_on='STORE_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a4f6212-c24f-4ee0-90a2-fc1274c6a0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k0/mx_3vf5n6wdg8wkvxkg7znt00000gp/T/ipykernel_95868/3316337609.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_data.WEEK_END_DATE = pd.to_datetime(merged_data.WEEK_END_DATE)\n"
     ]
    }
   ],
   "source": [
    "# convert to datetime\n",
    "merged_data.WEEK_END_DATE = pd.to_datetime(merged_data.WEEK_END_DATE)\n",
    "\n",
    "\n",
    "# create an array of unique week dates\n",
    "week = merged_data.WEEK_END_DATE.unique()\n",
    "\n",
    "merged_data['year'] = merged_data['WEEK_END_DATE'].dt.year\n",
    "merged_data['week_number'] = merged_data['WEEK_END_DATE'].dt.isocalendar().week\n",
    "\n",
    "merged_data = merged_data.sort_values(by=['UPC', 'STORE_NUM', 'year', 'week_number'])\n",
    "merged_data['units_sold_prev_year'] = merged_data.groupby(['UPC', 'STORE_NUM', 'week_number'])['UNITS'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deb46f2-ad54-4421-ad3f-3cdc53ef8bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "694d1f63-9ec3-48a9-915c-b6bfe013cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert all the categorical data using one-hot encoding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7f489d8b-81df-4655-97d0-5fe52fae224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "def validation_df(data, week, no_of_months, no_of_validation):\n",
    "    \n",
    "    model_set = []\n",
    "    set_n = 1\n",
    "    for w in range(len(week)-1,0,-1):\n",
    "        x_data = {}\n",
    "\n",
    "        x_data['train_start'] = week[w-3-4*no_of_months]\n",
    "        x_data['train_end'] = week[w-4]\n",
    "        x_data['validate_week'] = week[w-2]\n",
    "        x_data['test_week'] = week[w]\n",
    "        x_data['no_days_train'] = x_data['train_end'] - x_data['train_start']\n",
    "        x_data['set_no'] = 'set'+str(set_n)\n",
    "        set_n +=1\n",
    "        model_set.append(x_data)\n",
    "        if(len(model_set) == no_of_validation):\n",
    "            break\n",
    "        \n",
    "        \n",
    "    datapoints = []\n",
    "\n",
    "    for s in model_set :\n",
    "        x = {}\n",
    "        train_set = data[(data.WEEK_END_DATE >= s['train_start']) & (data.WEEK_END_DATE <= s['train_end'])]\n",
    "        x['train_shape'] = train_set.shape[0]\n",
    "        x['validation_shape']  = data[data.WEEK_END_DATE == s['validate_week']].shape[0]\n",
    "        x['test_shape'] = data[data.WEEK_END_DATE == s['test_week']].shape[0]\n",
    "        x.update(s)\n",
    "        datapoints.append(x)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(datapoints)\n",
    "    df['no_days_train'] = df['no_days_train'] + timedelta(days=7)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88330144-fff9-4452-8d1e-bb3e4568a090",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb029ddd-c783-4349-ae08-6b6ba4917f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0efbb0-9ed5-4aac-8fa5-8bd79fc21533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c114cae4-a4b1-4ff5-866c-b7f610c36e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function to calculate the root mean squared log error\n",
    "def get_msle(true, predicted) :\n",
    "    return np.sqrt(msle(true, predicted))\n",
    "\n",
    "# function to return the columns on which the model is trained\n",
    "def get_colums(data):\n",
    "    print('\\n####### The model is trained on Following Columns: ###########\\n')\n",
    "    print(data.columns)\n",
    "    print('===============================================================')\n",
    "\n",
    "\n",
    "# function to train the model \n",
    "# it will calculate and return the RMSLE on train and validation set    \n",
    "def my_model(train_d, validate_d, model):    \n",
    "    train_x = train_d.drop(columns=['WEEK_END_DATE', 'UNITS'])\n",
    "    train_y = train_d['UNITS']\n",
    "    \n",
    "    valid_x = validate_d.drop(columns=['WEEK_END_DATE', 'UNITS'])\n",
    "    valid_y = validate_d['UNITS']\n",
    "    \n",
    "    model.fit(train_x, train_y)\n",
    "    \n",
    "    predict_train = model.predict(train_x)\n",
    "    predict_train = predict_train.clip(min=0)\n",
    "            \n",
    "    predict_validate = model.predict(valid_x)\n",
    "    predict_validate = predict_validate.clip(min=0)\n",
    "    \n",
    "    return get_msle(train_y, predict_train), get_msle(valid_y, predict_validate), train_x\n",
    "    \n",
    "    \n",
    "    \n",
    "# function will extract the train and validation set using validation set dataframe\n",
    "# The defined model will train on each of the set and the average RMSLE on train and validate set will be returned\n",
    "def train_model(df, data, model):\n",
    "    \n",
    "    model_results_train = []\n",
    "    model_results_valid = []\n",
    "    for row in tqdm(range(df.shape[0]),leave=False, desc='training_model'):\n",
    "        \n",
    "        row = df.iloc[row]\n",
    "        train_set = data[(data.WEEK_END_DATE >= row['train_start']) & (data.WEEK_END_DATE <= row['train_end'])]\n",
    "        validate_set = data[data.WEEK_END_DATE == row['validate_week']]        \n",
    "        train, valid, data_train = my_model(train_set,validate_set, model)\n",
    "        model_results_train.append(train)\n",
    "        model_results_valid.append(valid)\n",
    "        \n",
    "    return np.mean(model_results_train) , np.mean(model_results_valid), data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa75e2-261b-4f57-ac43-c4a5ddb6ee68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d58abc-bfba-44e4-80ba-9e733f8d85b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf3c42-76e7-487f-8524-3ce9f28db4b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "80c67430-6c0c-4053-85a3-8e073994cd9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WEEK_END_DATE                  datetime64[ns]\n",
       "STORE_NUM                               int64\n",
       "UPC                                     int64\n",
       "BASE_PRICE                            float64\n",
       "FEATURE                                 int64\n",
       "DISPLAY                                 int64\n",
       "UNITS                                   int64\n",
       "DESCRIPTION                            object\n",
       "MANUFACTURER                           object\n",
       "CATEGORY                               object\n",
       "SUB_CATEGORY                           object\n",
       "PRODUCT_SIZE                          float64\n",
       "num_alternatives                        int64\n",
       "num_lower_size_alternatives             int64\n",
       "STORE_ID                                int64\n",
       "STORE_NAME                             object\n",
       "ADDRESS_CITY_NAME                      object\n",
       "ADDRESS_STATE_PROV_CODE                object\n",
       "MSA_CODE                                int64\n",
       "SEG_VALUE_NAME                         object\n",
       "PARKING_SPACE_QTY                     float64\n",
       "SALES_AREA_SIZE_NUM                     int64\n",
       "AVG_WEEKLY_BASKETS                      int64\n",
       "year                                    int32\n",
       "week_number                            UInt32\n",
       "units_sold_prev_year                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.dtypes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd1fd13-8a5c-4c88-b49c-1ac383863e29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d031461b-d140-4662-9cae-fe0d785eb8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b45e80-ad45-4fd9-bbf1-f01dd7d01e78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b3f261d-4557-4f27-bbc4-52b73b0f4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Step 1: Drop Unnecessary Columns\n",
    "\n",
    "columns_to_drop = ['STORE_NUM', 'UPC', 'DESCRIPTION', 'CATEGORY', 'STORE_ID', 'STORE_NAME','ADDRESS_CITY_NAME', 'ADDRESS_STATE_PROV_CODE', 'MSA_CODE', 'year']\n",
    "merged_data = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ca0b7ed4-8c3e-4aaf-b77f-6fd4ffb9a985",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['MANUFACTURER', 'SUB_CATEGORY', 'SEG_VALUE_NAME'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 2: One-Hot Encoding\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m merged_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMANUFACTURER\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSUB_CATEGORY\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSEG_VALUE_NAME\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/reshape/encoding.py:164\u001b[0m, in \u001b[0;36mget_dummies\u001b[0;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 164\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name: \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/frame.py:3899\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   3898\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 3899\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3901\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   3902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/indexes/base.py:6115\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6113\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6115\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6117\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6119\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/pandas/core/indexes/base.py:6176\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6174\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[1;32m   6175\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 6176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6178\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m   6179\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['MANUFACTURER', 'SUB_CATEGORY', 'SEG_VALUE_NAME'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "# Step 2: One-Hot Encoding\n",
    "merged_data = pd.get_dummies(merged_data, columns=['MANUFACTURER', 'SUB_CATEGORY', 'SEG_VALUE_NAME'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "769e7792-6690-4202-9a8a-b8609994e319",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merged_data -- drop --  'week_number'\n",
    "\n",
    "## merged_data -- MANUFACTURER,SUB_CATEGORY,SEG_VALUE_NAME\n",
    "\n",
    "## Convert to int BASE_PRICE,FEATURE,DISPLAY,UNITS,PRODUCT_SIZE,num_alternatives,num_lower_size_alternatives,PARKING_SPACE_QTY,\n",
    "## SALES_AREA_SIZE_NUM,AVG_WEEKLY_BASKETS,'units_sold_prev_year'\n",
    "\n",
    "\n",
    "## new columns units_sold_prev_year,PRODUCT_SIZE,PRODUCT_SIZE,PARKING_SPACE_QTY,num_alternatives,num_lower_size_alternatives,SEG_VALUE_NAME,units_sold_prev_year\n",
    "\n",
    "\n",
    "# Step 3: Convert Specified Columns to Float\n",
    "columns_to_convert = ['BASE_PRICE', 'UNITS', 'PRODUCT_SIZE', 'num_alternatives','num_lower_size_alternatives', 'PARKING_SPACE_QTY', 'SALES_AREA_SIZE_NUM','AVG_WEEKLY_BASKETS', 'units_sold_prev_year']\n",
    "merged_data[columns_to_convert] = merged_data[columns_to_convert].astype(float)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "936e156b-3786-44e7-8488-097d66e705d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEK_END_DATE</th>\n",
       "      <th>BASE_PRICE</th>\n",
       "      <th>FEATURE</th>\n",
       "      <th>DISPLAY</th>\n",
       "      <th>UNITS</th>\n",
       "      <th>PRODUCT_SIZE</th>\n",
       "      <th>num_alternatives</th>\n",
       "      <th>num_lower_size_alternatives</th>\n",
       "      <th>PARKING_SPACE_QTY</th>\n",
       "      <th>SALES_AREA_SIZE_NUM</th>\n",
       "      <th>...</th>\n",
       "      <th>SUB_CATEGORY_ADULT CEREAL</th>\n",
       "      <th>SUB_CATEGORY_ALL FAMILY CEREAL</th>\n",
       "      <th>SUB_CATEGORY_KIDS CEREAL</th>\n",
       "      <th>SUB_CATEGORY_MOUTHWASH/RINSES AND SPRAYS</th>\n",
       "      <th>SUB_CATEGORY_MOUTHWASHES (ANTISEPTIC)</th>\n",
       "      <th>SUB_CATEGORY_PIZZA/PREMIUM</th>\n",
       "      <th>SUB_CATEGORY_PRETZELS</th>\n",
       "      <th>SEG_VALUE_NAME_MAINSTREAM</th>\n",
       "      <th>SEG_VALUE_NAME_UPSCALE</th>\n",
       "      <th>SEG_VALUE_NAME_VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-01-14</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1640</th>\n",
       "      <td>2009-01-21</td>\n",
       "      <td>0.100996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3276</th>\n",
       "      <td>2009-01-28</td>\n",
       "      <td>0.071124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4912</th>\n",
       "      <td>2009-02-04</td>\n",
       "      <td>0.073969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6552</th>\n",
       "      <td>2009-02-11</td>\n",
       "      <td>0.091038</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.097177</td>\n",
       "      <td>0.183985</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WEEK_END_DATE  BASE_PRICE  FEATURE  DISPLAY     UNITS  PRODUCT_SIZE  \\\n",
       "0       2009-01-14    0.100996        0        0  0.007222      0.028056   \n",
       "1640    2009-01-21    0.100996        0        0  0.013333      0.028056   \n",
       "3276    2009-01-28    0.071124        0        0  0.003889      0.028056   \n",
       "4912    2009-02-04    0.073969        0        0  0.006667      0.028056   \n",
       "6552    2009-02-11    0.091038        0        0  0.008889      0.028056   \n",
       "\n",
       "      num_alternatives  num_lower_size_alternatives  PARKING_SPACE_QTY  \\\n",
       "0                  1.0                          0.2           0.097177   \n",
       "1640               1.0                          0.2           0.097177   \n",
       "3276               1.0                          0.2           0.097177   \n",
       "4912               1.0                          0.2           0.097177   \n",
       "6552               1.0                          0.2           0.097177   \n",
       "\n",
       "      SALES_AREA_SIZE_NUM  ...  SUB_CATEGORY_ADULT CEREAL  \\\n",
       "0                0.183985  ...                      False   \n",
       "1640             0.183985  ...                      False   \n",
       "3276             0.183985  ...                      False   \n",
       "4912             0.183985  ...                      False   \n",
       "6552             0.183985  ...                      False   \n",
       "\n",
       "      SUB_CATEGORY_ALL FAMILY CEREAL  SUB_CATEGORY_KIDS CEREAL  \\\n",
       "0                              False                     False   \n",
       "1640                           False                     False   \n",
       "3276                           False                     False   \n",
       "4912                           False                     False   \n",
       "6552                           False                     False   \n",
       "\n",
       "      SUB_CATEGORY_MOUTHWASH/RINSES AND SPRAYS  \\\n",
       "0                                        False   \n",
       "1640                                     False   \n",
       "3276                                     False   \n",
       "4912                                     False   \n",
       "6552                                     False   \n",
       "\n",
       "      SUB_CATEGORY_MOUTHWASHES (ANTISEPTIC)  SUB_CATEGORY_PIZZA/PREMIUM  \\\n",
       "0                                     False                       False   \n",
       "1640                                  False                       False   \n",
       "3276                                  False                       False   \n",
       "4912                                  False                       False   \n",
       "6552                                  False                       False   \n",
       "\n",
       "      SUB_CATEGORY_PRETZELS  SEG_VALUE_NAME_MAINSTREAM  \\\n",
       "0                      True                      False   \n",
       "1640                   True                      False   \n",
       "3276                   True                      False   \n",
       "4912                   True                      False   \n",
       "6552                   True                      False   \n",
       "\n",
       "      SEG_VALUE_NAME_UPSCALE  SEG_VALUE_NAME_VALUE  \n",
       "0                      False                  True  \n",
       "1640                   False                  True  \n",
       "3276                   False                  True  \n",
       "4912                   False                  True  \n",
       "6552                   False                  True  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Normalize the Float Columns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()  # You can also use MinMaxScaler() if you prefer\n",
    "merged_data[columns_to_convert] = scaler.fit_transform(merged_data[columns_to_convert])\n",
    "\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2f923-d816-4798-afa6-f016d4fc18a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc10aa50-d920-4dc1-a10d-8332b3f2dc95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e2bcc4f1-0863-4cb3-8b88-180a25eb3f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WEEK_END_DATE                               datetime64[ns]\n",
       "BASE_PRICE                                         float64\n",
       "FEATURE                                              int64\n",
       "DISPLAY                                              int64\n",
       "UNITS                                              float64\n",
       "PRODUCT_SIZE                                       float64\n",
       "num_alternatives                                   float64\n",
       "num_lower_size_alternatives                        float64\n",
       "PARKING_SPACE_QTY                                  float64\n",
       "SALES_AREA_SIZE_NUM                                float64\n",
       "AVG_WEEKLY_BASKETS                                 float64\n",
       "week_number                                         UInt32\n",
       "units_sold_prev_year                               float64\n",
       "MANUFACTURER_FRITO LAY                                bool\n",
       "MANUFACTURER_GENERAL MI                               bool\n",
       "MANUFACTURER_KELLOGG                                  bool\n",
       "MANUFACTURER_P & G                                    bool\n",
       "MANUFACTURER_PRIVATE LABEL                            bool\n",
       "MANUFACTURER_SNYDER S                                 bool\n",
       "MANUFACTURER_TOMBSTONE                                bool\n",
       "MANUFACTURER_TONYS                                    bool\n",
       "MANUFACTURER_WARNER                                   bool\n",
       "SUB_CATEGORY_ADULT CEREAL                             bool\n",
       "SUB_CATEGORY_ALL FAMILY CEREAL                        bool\n",
       "SUB_CATEGORY_KIDS CEREAL                              bool\n",
       "SUB_CATEGORY_MOUTHWASH/RINSES AND SPRAYS              bool\n",
       "SUB_CATEGORY_MOUTHWASHES (ANTISEPTIC)                 bool\n",
       "SUB_CATEGORY_PIZZA/PREMIUM                            bool\n",
       "SUB_CATEGORY_PRETZELS                                 bool\n",
       "SEG_VALUE_NAME_MAINSTREAM                             bool\n",
       "SEG_VALUE_NAME_UPSCALE                                bool\n",
       "SEG_VALUE_NAME_VALUE                                  bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "merged_data.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9493e50a-43e6-48af-b8c8-e9729cf24661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9d55eaf-39e9-4c4d-bc39-4d727709c9cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_model:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on train set: with the new columns  0.0036021292004435805\n",
      "RMSLE on validation set: with the new columns  0.013516333850542015\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "features_with_new_cols = merged_data\n",
    "\n",
    "# Features without the new columns\n",
    "features_without_new_cols = merged_data.drop(columns=['num_alternatives','num_lower_size_alternatives','week_number','units_sold_prev_year','PARKING_SPACE_QTY','week_number'])\n",
    "\n",
    "# Split the data into training and testing sets for both versions\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "model_RFR = RandomForestRegressor(max_depth=15, n_estimators=75, n_jobs=-1)\n",
    "\n",
    "valid_df = validation_df(features_with_new_cols, week, no_of_months=2, no_of_validation= 14)\n",
    "\n",
    "rmsle_train, rmsle_valid, data_train = train_model(valid_df,features_with_new_cols, model_RFR)\n",
    "\n",
    "print('RMSLE on train set: with the new columns ', rmsle_train)\n",
    "print('RMSLE on validation set: with the new columns ', rmsle_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c5dc1a25-0c5c-4c42-afde-8d781e872437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_model:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE on train set: without the new columns   0.005620156787588419\n",
      "RMSLE on validation set: without the new columns  0.0126781677821912\n"
     ]
    }
   ],
   "source": [
    "model_RFR = RandomForestRegressor(max_depth=15, n_estimators=75, n_jobs=-1)\n",
    "\n",
    "valid_df = validation_df(features_without_new_cols, week, no_of_months=2, no_of_validation= 14)\n",
    "\n",
    "rmsle_train, rmsle_valid, data_train = train_model(valid_df,features_without_new_cols, model_RFR)\n",
    "\n",
    "print('RMSLE on train set: without the new columns  ', rmsle_train)\n",
    "print('RMSLE on validation set: without the new columns ', rmsle_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b730a7-f449-4091-b8e4-4a95e37799fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
